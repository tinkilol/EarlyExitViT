{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e93d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch_size BATCH_SIZE] [--lr LR]\n",
      "                             [--weight_decay WEIGHT_DECAY] [--clip CLIP]\n",
      "                             [--epochs EPOCHS] [--seed SEED] [--save SAVE]\n",
      "                             [--fox FOX] [--train TRAIN]\n",
      "                             [--test_model TEST_MODEL] [--imagenet IMAGENET]\n",
      "                             [--num_pred NUM_PRED]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/corneliusbencsik/Library/Jupyter/runtime/kernel-ac43cea8-faac-4292-a99e-f854bb1b4e69.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "from litdata import litdata\n",
    "import torchvision . transforms as T\n",
    "from torch import nn\n",
    "import timm\n",
    "\n",
    "from useful_functions import seed_everything, train, evaluate, train_epochs\n",
    "from model import Stacked_ViT, Big_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description = \"Train model\")\n",
    "    parser.add_argument(\"--batch_size\", default = 256)\n",
    "    parser.add_argument(\"--lr\", default = 0.000001)\n",
    "    parser.add_argument(\"--weight_decay\", default = 0.2)\n",
    "    parser.add_argument(\"--clip\", default = 100)\n",
    "    parser.add_argument(\"--epochs\", default = 100)\n",
    "    parser.add_argument(\"--seed\", default = 5310)\n",
    "    parser.add_argument(\"--save\", default = True)\n",
    "    parser.add_argument(\"--fox\", default = True)\n",
    "    parser.add_argument(\"--train\", default = True)\n",
    "    parser.add_argument(\"--test_model\", default = False)\n",
    "    parser.add_argument(\"--imagenet\", default = True)\n",
    "    parser.add_argument(\"--num_pred\", default = 12)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    seed_everything(args.seed)\n",
    "\n",
    "    print(\"Loading data ...\") \n",
    "    print(f\"batch size = {args.batch_size}\") \n",
    "    if args.fox:\n",
    "        data_path = \"/fp/projects01/ec232/data/\"\n",
    "\n",
    "    else:\n",
    "        #katinka\n",
    "        #data_path = \"C:\\Users\\laila\\Documents\\Studium\\5.Semester\\AdvancedDeepLearning\\g05-p3\"\n",
    "        #coco\n",
    "        data_path = \"../../../../../../Desktop/\"\n",
    "        #amir\n",
    "        #data_path = \"/Users/amir/Documents/UiO/IN5310 â€“ Advanced Deep Learning for Image Analysis/project3/\"\n",
    "\n",
    "    in_mean = [0.485, 0.456, 0.406]\n",
    "    in_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    postprocess = (\n",
    "        T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Resize((224, 224), antialias=True),\n",
    "            T.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x),\n",
    "            T.Normalize(in_mean, in_std),\n",
    "        ]),\n",
    "        nn.Identity(), \n",
    "    )\n",
    "\n",
    "    if args.imagenet:\n",
    "        dataset = \"IN1k\"\n",
    "        num_classes = 1000\n",
    "    else:\n",
    "        dataset = \"Caltech256\"\n",
    "        num_classes = 257\n",
    "\n",
    "    print(f\"\\ndataset = {dataset}\\nnumber of classes = {num_classes}\\nnumber of predictions = {args.num_pred}\\n\")\n",
    "    traindata = litdata.LITDataset(dataset, data_path, override_extensions = [\"jpg\", \"cls\"] ).map_tuple(*postprocess)\n",
    "    valdata = litdata.LITDataset(dataset, data_path, train=False, override_extensions = [\"jpg\", \"cls\"]).map_tuple(*postprocess)\n",
    "\n",
    "    train_loader = DataLoader(traindata, shuffle=True, batch_size = args.batch_size)\n",
    "    val_loader = DataLoader(valdata, shuffle=False, batch_size = args.batch_size)\n",
    "        \n",
    "    print(\"Loading data done\") \n",
    "\n",
    "    if args.train:\n",
    "        print(\"Loading model ...\")\n",
    "        args.num_classes = num_classes\n",
    "\n",
    "        tiny = 'vit_tiny_patch16_224'\n",
    "        base = \"vit_base_patch16_224\"\n",
    "\n",
    "        pretrained_model = tiny\n",
    "\n",
    "        print(f\"\\npretrained model = {pretrained_model}\\n\")\n",
    "\n",
    "        model = timm.create_model(pretrained_model, pretrained=True, num_classes = num_classes).to(device)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr = args.lr, weight_decay = args.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs * len(train_loader))\n",
    "\n",
    "        stacked_vit = Stacked_ViT(model, num_classes, args.num_pred)\n",
    "        stacked_vit = torch.nn.DataParallel(stacked_vit)\n",
    "\n",
    "        print(\"Loading model done\")\n",
    "\n",
    "        print(\"Training model ...\")\n",
    "        if args.imagenet:\n",
    "            evaluate(model, val_loader, args.num_pred)\n",
    "        else:                                                                                                               \n",
    "            train_acc, val_acc = train_epochs(args, model, loss, optimizer, scheduler, train_loader, val_loader, args.num_pred)\n",
    "        print(\"Training model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3e0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
